\documentclass{report}
\usepackage{amsmath}
\usepackage{txfonts}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{color}
\usepackage{parskip}
\setlength{\parskip}{1em}
\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}
\usepackage{multirow}
\newcommand\parrow[3][3ex]{%
 \begin{array}[t]{@{}c@{}} #2 \\
  \left\uparrow\vcenter{\hrule height #1}\right.\kern-\nulldelimiterspace\\
  \makebox[0pt]{\small#3}
  \end{array}%
}
\newcommand\parrowlong[3][6ex]{%
 \begin{array}[t]{@{}c@{}} #2 \\
  \left\uparrow\vcenter{\hrule height #1}\right.\kern-\nulldelimiterspace\\
  \makebox[0pt]{\small#3}
  \end{array}%
}

\geometry{a4paper, margin=1in}

\begin{document}

\setcounter{chapter}{3}

\chapter{Linear Algebra}

\section{Linear Dependence and Independence}

Let $\bar{V}_1, \bar{V}_2, \bar{V}_3, \ldots, \bar{V}_n$ be nonzero elements in vector space $V$ and $C_1, C_2, C_3, \ldots, C_n \in \mathbb{R}$

If the only solution to $C_1 \bar{V}_1+C_2 \bar{V}_2+C_3 \bar{V}_3+\ldots+ C_n \bar{V}_n=0$ is the trivial solution ( $C_1=C_2=\ldots=C_n=0$ ), the set of $\bar{V}_1, \ldots, \bar{V}_n$ is linearly independent. Otherwise they are linearly dependent.

\section{Wronskian}

If $W\left[f_1, f_2, f_3, \ldots, f_n\right]$ ever $\neq 0$, the set is linearly independent. If $W\left[f_1, f_2, f_3, \ldots, f_n\right]=0$ always and the set af functions are all analytic (can be expressed as a convergent power series on the domain of interest), the set is linearly dependent.

\emph{NB: $f_1, \ldots, f_n$ must be continuous and differentiable on $[a, b]$.}

\section{Dimension and Basis}

Dimension: The dimension of vector space $V$ is the cardinality of the basis of $V$. (number of basis vectors).

Corollary: Any set of vectors with cardinality $>\operatorname{dim}(V)$ is linearly dependent.

Corollary 2: The maximum number of linearly independent vectors is $\operatorname{dim}(V)$.

Basis: A set of linearly independent vectors that span $V$ is a basis of $V$. 

Corollary: All elements in $V$ can be expressed as a linear combination of the elements of a basis of $V$. (Unique to the basis).

i.e. $\begin{array}{l}
     \text{$\{\hat{\imath}, \hat{\jmath}\}$ is a basis in $\mathbb{R}^2$. So is any pair of non colinear vectors. } \\
     \text{$\{\hat{\imath}, \hat{\jmath}, \hat{k}\}$ is a basis in $\mathbb{R}^3$. So are any 3 non coplanar vectors.}
\end{array}$

\section{Linear Operators}

$\tau$ is an operator on $V$ if $\tau \bar{x} \in V$ where $\bar{X} \in V$.

If for any $\bar{x} \in V, c \in \mathbb{R}$.

$$
\tau\left(\bar{x}_1+\bar{x}_2\right)=\tau\left(\bar{x}_1\right)+\tau\left(\bar{x}_2\right) \text { and } \tau(c \bar{x})=c \tau(\bar{x}).
$$

%%%%%%%%%%%%%%%%%%%%

$\tau$ is a linear operator and the image of $\tau: V \rightarrow V$ forms a subspace.

Eg. The operator $\tau=\dfrac{d}{d x}$ is a linear operator on the vector space $V$ of polynomials of degree $n$ or less.

NB: So is the operator $\tau=\displaystyle\int^{x} d t$, but its image is not confined in $V$

$$
\begin{aligned}
& \tau=\dfrac{d}{d x}, \tau: V \rightarrow V \\
& \tau=\displaystyle\int^{x} d x, \tau: V \rightarrow W,\ W=p_{n+1}(x),\ V=p_{n}(x)
\end{aligned}
$$

\section{Null Spaces}

The null space of a linear operator $\mathcal{L}$ on $V$ is the set of elements $v \in V$ s.t. $\mathcal{L} v=\mathbb{O}$.

I.e. The null space of $\mathcal{L}=\dfrac{d}{d x}$ is $v=c,\ c \in \mathbb{R}$.

Obviously, since $\dfrac{d}{d x} c=\mathcal{L} c=0$. The derivative of a constant is zero.

\section{Gram-Schmidt Process}

By definition, $\langle X \mid Y\rangle=|X||Y| \cos (X, Y)$

And, $\langle X \mid X\rangle=|X|^{2},\quad \therefore|X|=\sqrt{\langle X \mid X\rangle}$

The distance between two elements (ie. functions) is:

$$
\operatorname{dist}(f, g)=|f-g|.
$$

The Gram-Schmidt process turns a basis into an orthogonal basis.

Given a basis $\left\{v_{1}, v_{2}, v_{3}, \ldots, v_{n}\right\} \xrightarrow{G-S}\left\{u_{1}, u_{2}, u_{3}, \ldots, u_{n}\right\}$

Orthogonality is defined as $\left\langle u_{n}, u_{k}\right\rangle=0$ if $n \neq k$. The Gram-Schmidt algorithm is as follows:

$$
\begin{aligned}
& u_{1}=v_{1} \\
& u_{2}=v_{2}-\dfrac{\left\langle v_{2}, u_{1}\right\rangle}{\left\langle u_{1}, u_{1}\right\rangle} u_{1} \\
& u_{3}=v_{3}-\dfrac{\left\langle v_{3}, u_{1}\right\rangle}{\left\langle u_{1}, u_{1}\right\rangle} u_{1}-\dfrac{\left\langle v_{3}, u_{2}\right\rangle}{\left\langle u_{2}, u_{2}\right\rangle} u_{2}
\end{aligned}
$$

Essentially it subtracts the non-orthogonal components of the vectors away. Note that the G-S process does not normalize the basis. That has to be done separately.

To normalize, $\varnothing_{1}=\dfrac{u_{1}}{\sqrt{\left\langle u_{1}, u_{1}\right\rangle}}$ for all $u_{n}$.

To get the ``best approximation'' of an element $f$ outside a vector space $V$ (ie. $x^{4}$ in $p_{3}(x)$ ):

$f \approx \sum\limits_{k=1}^{n} a_{k} \phi_{k} \quad$ where $a_{k}=\left\langle\phi_{k}, f\right\rangle$

NOTE: $\varnothing$ must be an orthonormal basis, not just orthogonal.

I.e. Estimate $\tau^{4}$ with $\varnothing=\left\{\frac{1}{\sqrt{2}}, \sqrt{\frac{3}{2}} \tau, \sqrt{\frac{5}{8}}\left(3 \tau^{2}-1\right), \sqrt{\frac{7}{8}}\left(5 \tau^{3}-3 \tau\right)\right\}$

$a_{1}=\left\langle\dfrac{1}{\sqrt{2}}, \tau^{4}\right\rangle$

$a_{2}=\left\langle\sqrt{\dfrac{3}{2}} \tau, \tau^{4}\right\rangle$, and so on for $a_{3}, a_{4}$.

\section{Eigenvalues/Eigenfunctions of Differential Equations.}

For the purposes of this course, consider a general solution like $\Psi(x, t)=\sum\limits_{n=1}^{\infty} A_{n} \sin \left(\dfrac{n \pi x}{L}\right) e^{\frac{-n^{2} \pi^{2}}{L^{2}}\cdot t}$\qquad BVP 1-A

The eigenvalue will be $\dfrac{n^{2} \pi^{2}}{L^{2}}$, the eigenfunction will be $\sin (\sqrt{\lambda} x) e^{-\lambda t}$.

Mathematically, it is in the form:

$$
\mathcal{L}[f(x)]=\lambda f(x)
$$

Where $\mathcal{L}$ is a linear operator (i.e. derivative), $\lambda$ is a scalar eigenvalue, $f(x)$ is the eigenfunction, maintaining shape under $\mathcal{L}$.

I.e. $\mathcal{L}=\dfrac{d^{2}}{d x^{2}}$

$$
\therefore \dfrac{d^{2} f(x)}{d x^{2}}=\lambda f(x)
$$

As always, there are 3 cases $(\lambda>0,\ \lambda=0,\ \lambda<0)$

The only oscillatory solution is $\underbrace{\lambda=-k^{2}}_{\text{eigenvalues}}$

$$\therefore f^{\prime \prime}(x)=-k^{2} f(x)$$

$$
f(x)=A\!\underbrace{\cos(kx)}_{\text{eigenfunction}}+B\!\underbrace{\sin(kx)}_{\text{eigenfunction}}.
$$

The specific values of $\lambda, A, B$ depend on the B.C.s.

I.e. with homogeneous Dirichlet conditions on $x \in[0, L]$ yields

$$
\begin{aligned}
& k=\dfrac{n \pi}{L} \Rightarrow \lambda=-\dfrac{n^{2} \pi^{2}}{L^{2}} \\
& f_{n}(x)=\sin \left(\dfrac{n \pi x}{L}\right).
\end{aligned}
$$

\section{Hermitian Operators}

A Hermitian operator $\mathcal{L}$ over an inner product is a linear operator with the property: $\langle X, \mathcal{L}[Y]\rangle=\langle\mathcal{L}[Y], X\rangle$

The inner product for functions is defined (with real values) by
\[
\langle f, g \rangle = \int_a^b f(x)\, g(x)\, w(x) \, dx,
\]
where \(w(x)\) is a given weight function. 

If \(\mathcal{L}\) is a Hermitian operator, then for all functions \(f(x)\) and \(g(x)\) in the domain of \(\mathcal{L}\), the following equality holds:
\[
\int_a^b f(x)\, \mathcal{L}[g](x) \, dx = \int_a^b \mathcal{L}[f](x)\, g(x) \, dx.
\]

\emph{NB, this is a tough criterion, most operators are not Hermitian.}

Hermitian operators are obviously not absolute. If the inner product is defined differently, a operator may cease to be Hermitian.

Hermitian operators have the following properties:

\begin{enumerate}
  \item \textbf{The eigenvalues of a Hermitian operator are real.} \\
    Let \(\mathcal{L}\) be a Hermitian operator on an inner product space and let \(f\) be an eigenvector of \(\mathcal{L}\) with eigenvalue \(\lambda\), i.e.,
    \[
    \mathcal{L}[f] = \lambda f.
    \]
    Then, using the properties of the inner product, we have
    \[
    \langle f, \mathcal{L}[f] \rangle = \langle f, \lambda f \rangle = \lambda \langle f, f \rangle.
    \]
    Since \(\mathcal{L}\) is Hermitian,
    \[
    \langle f, \mathcal{L}[f] \rangle = \langle \mathcal{L}[f], f \rangle = \langle \lambda f, f \rangle = \overline{\lambda}\langle f, f \rangle.
    \]
    Equating the two expressions and noting that \(\langle f, f \rangle \neq 0\) (since \(f\) is nonzero), we conclude
    \[
    \lambda = \overline{\lambda},
    \]
    which implies that \(\lambda\) is real, as only real numbers are equal to their complex conjugate.

  \item \textbf{The eigenvectors of a Hermitian operator corresponding to different eigenvalues are orthogonal.} \\
    Let \(f\) and \(g\) be eigenvectors of the Hermitian operator \(\mathcal{L}\) corresponding to distinct eigenvalues \(\lambda\) and \(\mu\) respectively:
    \[
    \mathcal{L}[f] = \lambda f \quad \text{and} \quad \mathcal{L}[g] = \mu g.
    \]
    Consider the inner product \(\langle f, \mathcal{L}[g] \rangle\). On one hand, using the eigenvalue equation for \(g\),
    \[
    \langle f, \mathcal{L}[g] \rangle = \langle f, \mu g \rangle = \mu \langle f, g \rangle.
    \]
    On the other hand, using the Hermitian property of \(\mathcal{L}\) and the eigenvalue equation for \(f\),
    \[
    \langle f, \mathcal{L}[g] \rangle = \langle \mathcal{L}[f], g \rangle = \langle \lambda f, g \rangle = \lambda \langle f, g \rangle.
    \]
    Equating these two expressions gives
    \[
    \lambda \langle f, g \rangle = \mu \langle f, g \rangle.
    \]
    Since \(\lambda \neq \mu\), it follows that
    \[
    \langle f, g \rangle = 0,
    \]
    meaning that \(f\) and \(g\) are orthogonal.
\end{enumerate}

An operator being Hermitian may depend on the boundary conditions imposed on the functions. For example, consider the operator
\[
\mathcal{L} = \frac{d^2}{dx^2}.
\]
For \(\mathcal{L}\) to be Hermitian, the boundary term that arises from integration by parts must vanish. To see this, let \(f\) and \(g\) be functions defined on \([0,L]\) and consider
\begin{align*}
\langle \mathcal{L}[f], g \rangle &= \int_0^L \frac{d^2 f}{dx^2}\, g(x)\, dx \\
&= \left[ f'(x) g(x) - f(x) g'(x) \right]_{0}^{L} + \int_0^L f(x) \frac{d^2 g}{dx^2}\, dx \quad \text{(by integration by parts)} \\
&= \text{B.T.} + \langle f, \mathcal{L}[g] \rangle,
\end{align*}
where the boundary term (B.T.) is given by
\[
\text{B.T.} = \left[ f'(x) g(x) - f(x) g'(x) \right]_{0}^{L}.
\]
Thus, for \(\mathcal{L}\) to be Hermitian (i.e., for
\[
\langle \mathcal{L}[f], g \rangle = \langle f, \mathcal{L}[g] \rangle \quad \text{for all } f, g),
\]
the boundary term must vanish:
\[
\left[ f'(x) g(x) - f(x) g'(x) \right]_{0}^{L} = 0.
\]
This condition depends on the specific boundary conditions imposed on the functions.


\section{Parseval's Theorem}

\emph{Optional. There is more to be covered but it gets pretty advanced and not too useful for people without a real analysis or advanced algebra background.}

For $f(x)$ piecewise smooth on $(0, L)$:

$
\begin{aligned}
& f(x)=\sum\limits_{n=1}^{\infty} b_{n} g_{n} \\
& \langle f(x) \mid f(x)\rangle=\left\langle f(x) \mid \sum\limits_{n=1}^{\infty} b_{n} g_{n}\right\rangle=\sum\limits_{n=1}^{\infty} b_{n}\left\langle f(x) \mid g_{n}\right\rangle=\sum\limits_{n=1}^{\infty} b_{n} \cdot \dfrac{L \overline{b_{n}}}{2}=\dfrac{L}{2} \sum\limits_{n=1}^{\infty}\left|b_{n}\right|^{2} \\
& \text{If} \left\langle g_{n} \mid f(x)\right\rangle=\dfrac{L}{2} b_{n} \text {, then }\left\langle f(x) \mid g_{n}\right\rangle=\dfrac{L}{2} \overline{b_{n}}
\end{aligned}
$

$\therefore \dfrac{2}{L}\langle f(x) \mid f(x)\rangle=\sum\limits_{n=1}^{\infty}\left|b_{n}\right|^{2}$

$\therefore \sum\limits_{n=1}^{\infty}\left|b_{n}\right|^{2}=\dfrac{2}{L} \displaystyle\int_{0}^{L}|f(x)|^{2} d x$ \quad Fourier transform is unitary.

\end{document}
